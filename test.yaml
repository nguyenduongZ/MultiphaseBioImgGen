model:
  name: imagen
  imagen:
    video: false
    timesteps: [1024, 512]
    image_sizes: [64, 256]
    random_crop_sizes: [null, 64]
    condition_on_text: true
    cond_drop_prob: 0.1
    text_encoder_name: google/t5-v1_1-large # google/t5-v1_1-base | microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract
    # text_encoder_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract 
    text_embed_dim: 1024
    loss_type: l2
    noise_schedules: cosine
    pred_objectives: noise
    lowres_noise_schedule: linear
    lowres_sample_noise_level: 0.2          # in the paper, they present a new trick where they noise the lowres conditioning image, and at sample time, fix it to a certain level (0.1 or 0.3) - the unets are also made to be conditioned on this noise level
    only_train_unet_number: None
    dynamic_thresholding_percentile: 0.95   # unsure what this was based on perusal of paper

    unets:
      - dim: 128
        cond_dim: 512
        dim_mults: [1, 2, 3, 4]
        num_resnet_blocks: 3
        layer_attns: [false, true, true, true]
        layer_cross_attns: [false, true, true, true]
        attn_heads: 8

      - dim: 128
        cond_dim: 512
        dim_mults: [1, 2, 4, 8]
        num_resnet_blocks: [2, 4, 8, 8]
        layer_attns: [false, false, false, true]
        layer_cross_attns: [false, false, false, true]
        attn_heads: 8

conductor:
  ###
  mode: training
  unet: 1
  cond_scale: 1.75
  seed: 42
  idx: 0
  iterations: 100000

data:
  name: vindr_multiphase