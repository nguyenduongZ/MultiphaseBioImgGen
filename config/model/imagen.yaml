model:
  model_type: Imagen
  Imagen:
    ## Architecture
    # U-Net 1
    unet1:
      dim: 128
      cond_dim: 512
      dim_mults: [1, 2, 4, 8]
      num_resnet_blocks: 3
      layer_attns: [False, True, True, True]
      layer_cross_attns: [False, True, True, True]

    # U-Net 2
    unet2:
      dim: 128
      cond_dim: 512
      dim_mults: [1, 2, 4, 8]
      num_resnet_blocks: [2, 4, 8, 8]
      layer_attns: [False, False, False, True]
      layer_cross_attns: [False, False, False, True]

    # Imagen Model
    imagen:

      # Parameter
      image_sizes: [64, 256]

      # Text Embedding
      text_embed_dim: 768                     # T5: 768
      text_encoder_name: google/t5-v1_1-base  # T5: google/t5-v1_1-base | OHE: ohe_encoder

      # Variables
      timesteps: 1000
      cond_drop_prob: 0.1
      loss_type: l2
      noise_schedules: cosine
      pred_objectives: noise
      lowres_noise_schedule: linear
      lowres_sample_noise_level: 0.2          # in the paper, they present a new trick where they noise the lowres conditioning image, and at sample time, fix it to a certain level (0.1 or 0.3) - the unets are also made to be conditioned on this noise level
      condition_on_text: True
      only_train_unet_number: None
      dynamic_thresholding_percentile: 0.95   # unsure what this was based on perusal of paper